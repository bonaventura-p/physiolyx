{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/physiolyx/src/old'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime \n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import Model, initializers, optimizers, regularizers\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Dropout, LSTM, TimeDistributed, Activation,Softmax\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sceneDict(table):\n",
    "    '''add descr'''\n",
    "    scene_dict = {0: 'Menu', 1: 'Goalkeeping', 2: 'Touch object', 3: 'Fruit picking', 4: 'Gym time trials',\n",
    "                  5: 'Calibration', 6: 'Sorting'}\n",
    "\n",
    "    for key in scene_dict.keys():\n",
    "        table.loc[table.scene_index == key, 'scene_index'] = scene_dict[key]\n",
    "\n",
    "    return table['scene_index']\n",
    "\n",
    "def rotRescalerML(val, D=360):\n",
    "    '''add descr'''\n",
    "    return (np.where(val > D / 2, (val - D), val))\n",
    "\n",
    "\n",
    "def valDivider(table, k=1000):\n",
    "    '''add descr'''\n",
    "\n",
    "    return table / k\n",
    "\n",
    "\n",
    "def metscoreCalc(scene, table):\n",
    "    '''add descr'''\n",
    "    #0 - Menu\n",
    "    #1 - Gym(goalkeeping)\n",
    "    #2 - TouchObject\n",
    "    #3 - Fruit picking\n",
    "    #4 - Gym_TimeTrials(goalkeeping time trials)\n",
    "    #5 - Calibration\n",
    "    #6 - Sorting\n",
    "    metscore_dict = {0: 1, 1: 2.5, 2: 2.5, 3: 3, 4: 2.5, 5: 1, 6: 2}\n",
    "\n",
    "    metscore = []\n",
    "    for row in range(len(table)):\n",
    "        metscore.append(metscore_dict[table[scene][row]] / 4320) #60*72\n",
    "\n",
    "    return metscore\n",
    "\n",
    "def tableReader(file, cols):\n",
    "    '''add descr'''\n",
    "    if cols is None:\n",
    "        cols = ['index', 'scene_index', 'time', 'ms_lastline', 'head_posx', \"head_posy\", \"head_posz\", \"head_rotx\",\n",
    "            \"head_roty\", \"head_rotz\", \"right_posx\", \"right_posy\", \"right_posz\", \"right_rotx\", \"right_roty\",\n",
    "            \"right_rotz\", \"left_posx\", \"left_posy\", \"left_posz\", \"left_rotx\", \"left_roty\", \"left_rotz\"]\n",
    "\n",
    "    table = pd.read_table(file, sep=',', header=0, names=cols)\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def tableProcessML(table, data):\n",
    "    '''add descr'''\n",
    "    '''data(dict): The Cloud Functions event payload.'''\n",
    "\n",
    "    ### 2. divide /1000 ###\n",
    "    colDivider = ['head_posx',\"head_posy\",\"head_posz\",\"head_rotx\",\"head_roty\",\"head_rotz\",\n",
    "        \"right_posx\",\"right_posy\",\"right_posz\",\"right_rotx\",\"right_roty\",\"right_rotz\",\n",
    "        \"left_posx\",\"left_posy\",\"left_posz\",\"left_rotx\",\"left_roty\",\"left_rotz\"]\n",
    "    table.loc[:, colDivider] = valDivider(table.loc[:, colDivider])\n",
    "\n",
    "    ### 3. format time ###\n",
    "    table['time'] = pd.to_datetime(table['time'], format=\"%H:%M:%S\").dt.time #do we really need this column?\n",
    "\n",
    "    ### 4. create date ###\n",
    "    table['date'] = pd.to_datetime(data['name'][12:22], format = \"%d-%m-%Y\")\n",
    "\n",
    "    ### 5. create seconds ###\n",
    "    #on hold for now\n",
    "    #timedelta = pd.to_timedelta(table.time.astype(str))\n",
    "    #diff = timedelta.diff().fillna(pd.Timedelta(seconds=0)) / 1e9\n",
    "    #table['seconds'] = np.cumsum(diff).astype(int)\n",
    "\n",
    "    ### 6. rescale rotations ###\n",
    "    cols = [\"head_rotx\", \"head_roty\", \"head_rotz\", \"right_rotx\", \"right_roty\", \"right_rotz\",\n",
    "            \"left_rotx\", \"left_roty\", \"left_rotz\"]\n",
    "\n",
    "    for col in cols:\n",
    "        table[col] = rotRescalerML(table[col])\n",
    "\n",
    "    ### 7. compute MET score at frame level ###\n",
    "    table['met_score'] = metscoreCalc('scene_index', table)\n",
    "\n",
    "    ### 8. replace scene_index with string names ###\n",
    "    table['scene_index'] = sceneDict(table)\n",
    "\n",
    "    ### 9. create id column ###\n",
    "    table['id'] = 1 #in production this should come from the quest\n",
    "\n",
    "    ### 10. drop unused columns ###\n",
    "    table = table.drop('index ms_lastline'.split(), axis=1)\n",
    "\n",
    "    return table\n",
    "\n",
    "def TrainPreprocess(df, cols, timeSteps=72, step=14, div=70, method='last'):\n",
    "    '''preprocessing'''\n",
    "\n",
    "    if cols is None:\n",
    "        cols = [\"head_rotx\",\"head_roty\",\"head_rotz\",\"head_posx\",\"head_posy\",\"head_posz\"]\n",
    "        \n",
    "    features= len(cols)\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    print('Preprocessing started')\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    #normalise data otherwise loss= nan\n",
    "    for col in cols:\n",
    "        df[col] = (df[col] - df[col].min())/(df[col].max()-df[col].min())\n",
    "\n",
    "    #reshuffle?\n",
    "    np.random.shuffle(df.values.reshape(-1,int(np.floor(df.shape[0]/div)),df.shape[1]))\n",
    "\n",
    "\n",
    "    #we reshape into 3d arrays of length equal to timesteps. final df is= (N*timesteps*6)\n",
    "    coldict = {}\n",
    "    for i in range(0, len(df) - timeSteps, step):\n",
    "        for col in cols:\n",
    "            coldict[str(col[5:])] = table[col].values[i: i + timeSteps]\n",
    "       \n",
    "            segments.append(coldict[str(col[5:])])\n",
    "        \n",
    "        if method == 'max':\n",
    "            label = stats.mode(df['action'][i:i + timeSteps])[0][0]\n",
    "        else:\n",
    "            label = df['action'].iloc[i + timeSteps]\n",
    "        \n",
    "        labels.append(label)\n",
    "        \n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, timeSteps, features)\n",
    "    \n",
    "    labels = pd.get_dummies(labels)\n",
    "    truelabels= pd.get_dummies(labels).idxmax(1)\n",
    "    labels = np.asarray(labels, dtype = np.float32)\n",
    "\n",
    "    print('Preprocessing completed')\n",
    "\n",
    "    return reshaped_segments, labels, truelabels\n",
    "\n",
    "\n",
    "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
    "    \"\"\"Downloads a blob from the bucket.\"\"\"\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.get_blob(source_blob_name)\n",
    "\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print('Blob {} downloaded to {}.'.format(\n",
    "        source_blob_name,\n",
    "        destination_file_name))\n",
    "    \n",
    "    \n",
    "def trainer(model, epochs=40, batch_size=12):\n",
    "    '''removed .hdf5 from filename'''\n",
    "    callbacks = ModelCheckpoint('model_ep{epoch:02d}_val{val_categorical_accuracy:.2f}', monitor='val_categorical_accuracy', verbose=0,\n",
    "                                save_best_only=True, save_weights_only=True, mode='max')\n",
    "    history = model.fit(X,y, validation_split = 0.2, batch_size = 12,\n",
    "                epochs = epochs, callbacks = [callbacks])\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "def upload_blob(bucket, infile, outfile):\n",
    "    '''add descr'''\n",
    "    \n",
    "    client = storage.Client()\n",
    "    outbucket = client.get_bucket(bucket)\n",
    "    outblob = outbucket.blob(outfile)\n",
    "    \n",
    "    with open(infile, \"rb\") as out:\n",
    "        outblob.upload_from_file(out)\n",
    "    \n",
    "    print('File {} uploaded to {} as {}.'.format(\n",
    "        infile, bucket, outfile))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob moniLabData 20-03-2020.txt downloaded to file.txt.\n"
     ]
    }
   ],
   "source": [
    "colslab = ['index','scene_index','time','ms_lastline','head_posx',\"head_posy\",\"head_posz\",\"head_rotx\",\"head_roty\",\"head_rotz\",\n",
    "        \"right_posx\",\"right_posy\",\"right_posz\",\"right_rotx\",\"right_roty\",\"right_rotz\",\n",
    "        \"left_posx\",\"left_posy\",\"left_posz\",\"left_rotx\",\"left_roty\",\"left_rotz\",'timedel','action']\n",
    "\n",
    "download_blob(data['bucket'],data['name'],'file.txt')\n",
    "table = tableReader('file.txt',cols=colslab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = tableProcessML(table,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "table= table.loc[:,['action',\"head_rotx\",\"head_roty\",\"head_rotz\"]]\n",
    "\n",
    "table = table[table.action != 'STILL']\n",
    "\n",
    "table = table[0:11130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action\n",
       "3DLEX     145\n",
       "3DLFL     503\n",
       "3DREX     361\n",
       "3DRFL     359\n",
       "EXTE     2230\n",
       "FLEX     1799\n",
       "LBEN     1010\n",
       "LROT     1945\n",
       "RBEN      864\n",
       "RROT     1914\n",
       "dtype: int64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.groupby('action').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "colspre = [\"head_rotx\",\"head_roty\",\"head_rotz\"]\n",
    "\n",
    "timeSteps = 72\n",
    "n_features = len(colspre)\n",
    "n_classes = table.action.unique().size\n",
    "\n",
    "method = 'last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing started\n",
      "Preprocessing completed\n"
     ]
    }
   ],
   "source": [
    "X,y, true = TrainPreprocess(table, cols=colspre, timeSteps=timeSteps, method = method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepConvLSTM(Model):\n",
    "  def __init__(self):\n",
    "    super(DeepConvLSTM, self).__init__()\n",
    "    self.c1 = Conv1D(8, 1,input_shape=(timeSteps, n_features), kernel_regularizer=regularizers.l2(0.02), activation='relu', kernel_initializer='orthogonal') #ordo filters=64, kernel_size = 5\n",
    "    self.c2 = Conv1D(8, 3,kernel_regularizer=regularizers.l2(0.02), activation='relu', kernel_initializer='orthogonal')\n",
    "    #self.c3 = Conv1D(8, 3,kernel_regularizer=regularizers.l2(0.02), activation='relu', kernel_initializer='orthogonal')\n",
    "    #self.c4 = Conv1D(8, 3, activation='relu', kernel_initializer='orthogonal')\n",
    "    self.do1 = Dropout(0.5)\n",
    "    self.r1 = LSTM(16, activation='tanh', kernel_regularizer=regularizers.l2(0.02), return_sequences = True) #ordo cells=128\n",
    "    self.do2 = Dropout(0.5)\n",
    "    self.r2 = LSTM(16, activation='tanh', kernel_regularizer=regularizers.l2(0.02),  return_sequences = False)\n",
    "    self.sm = Dense(n_classes, activation='softmax')\n",
    "    \n",
    "  def call(self, x):\n",
    "    x = self.c1(x)\n",
    "    x = self.c2(x)\n",
    "    #x = self.c3(x)\n",
    "    #x = self.c4(x)\n",
    "    x = self.do1(x)\n",
    "    x = self.r1(x)\n",
    "    x = self.do2(x)\n",
    "    x = self.r2(x)\n",
    "    \n",
    "    return self.sm(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(Model):\n",
    "  def __init__(self):\n",
    "    super(SimpleLSTM, self).__init__()\n",
    "    #self.c1 = Conv1D(8, 1, kernel_regularizer=regularizers.l2(0.02), activation='relu', kernel_initializer='orthogonal') #ordo filters=64, kernel_size = 5\n",
    "    #self.c2 = Conv1D(8, 3,kernel_regularizer=regularizers.l2(0.02), activation='relu', kernel_initializer='orthogonal')\n",
    "    #self.c3 = Conv1D(8, 3,kernel_regularizer=regularizers.l2(0.02), activation='relu', kernel_initializer='orthogonal')\n",
    "    #self.c4 = Conv1D(8, 3, activation='relu', kernel_initializer='orthogonal')\n",
    "    #self.do1 = Dropout(0.5)\n",
    "    self.r1 = LSTM(32,input_shape=(timeSteps, n_features), activation='tanh', kernel_regularizer=regularizers.l2(0.02), return_sequences = True) #ordo cells=128\n",
    "    #self.do2 = Dropout(0.5)\n",
    "    self.r2 = LSTM(32, activation='tanh', kernel_regularizer=regularizers.l2(0.02),  return_sequences = False)\n",
    "    self.sm = Dense(n_classes, activation='softmax')\n",
    "    \n",
    "  def call(self, x):\n",
    "    #x = self.c1(x)\n",
    "    #x = self.c2(x)\n",
    "    #x = self.c3(x)\n",
    "    #x = self.c4(x)\n",
    "   # x = self.do1(x)\n",
    "    x = self.r1(x)\n",
    "    #x = self.do2(x)\n",
    "    x = self.r2(x)\n",
    "    \n",
    "    return self.sm(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(Model):\n",
    "  def __init__(self):\n",
    "    super(SimpleLSTM, self).__init__()\n",
    "    #self.c1 = Conv1D(8, 1, kernel_regularizer=regularizers.l2(0.02), activation='relu', kernel_initializer='orthogonal') #ordo filters=64, kernel_size = 5\n",
    "    #self.c2 = Conv1D(8, 3,kernel_regularizer=regularizers.l2(0.02), activation='relu', kernel_initializer='orthogonal')\n",
    "    #self.c3 = Conv1D(8, 3,kernel_regularizer=regularizers.l2(0.02), activation='relu', kernel_initializer='orthogonal')\n",
    "    #self.c4 = Conv1D(8, 3, activation='relu', kernel_initializer='orthogonal')\n",
    "    #self.do1 = Dropout(0.5)\n",
    "    self.r1 = LSTM(32,input_shape=(timeSteps, n_features), activation='tanh', kernel_regularizer=regularizers.l2(0.02), return_sequences = True) #ordo cells=128\n",
    "    #self.do2 = Dropout(0.5)\n",
    "    self.r2 = LSTM(32, activation='tanh', kernel_regularizer=regularizers.l2(0.02),  return_sequences = False)\n",
    "    self.sm = Dense(n_classes, activation='softmax')\n",
    "    \n",
    "  def call(self, x):\n",
    "    #x = self.c1(x)\n",
    "    #x = self.c2(x)\n",
    "    #x = self.c3(x)\n",
    "    #x = self.c4(x)\n",
    "   # x = self.do1(x)\n",
    "    x = self.r1(x)\n",
    "    #x = self.do2(x)\n",
    "    x = self.r2(x)\n",
    "    \n",
    "    return self.sm(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLSTM()\n",
    "# define loss and optimizer\n",
    "adam = optimizers.Adam(learning_rate=0.001) #(ordo learning_rate=0.01, decay=0.9)\n",
    "\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['categorical_accuracy']) #or categorical_accuracy? #sparse categorical crossentropy if labels not one-hot encoded\n",
    "# fit the model\n",
    "#model.save_weights('model.h5')\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 632 samples, validate on 158 samples\n",
      "Epoch 1/20\n",
      "632/632 [==============================] - 7s 11ms/sample - loss: 3.0304 - categorical_accuracy: 0.2104 - val_loss: 2.7364 - val_categorical_accuracy: 0.2025\n",
      "Epoch 2/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 2.4680 - categorical_accuracy: 0.2484 - val_loss: 2.5318 - val_categorical_accuracy: 0.1962\n",
      "Epoch 3/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 2.2121 - categorical_accuracy: 0.2642 - val_loss: 2.4249 - val_categorical_accuracy: 0.2152\n",
      "Epoch 4/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 2.0928 - categorical_accuracy: 0.2737 - val_loss: 2.3883 - val_categorical_accuracy: 0.2468\n",
      "Epoch 5/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.9931 - categorical_accuracy: 0.3054 - val_loss: 2.3338 - val_categorical_accuracy: 0.2278\n",
      "Epoch 6/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.9535 - categorical_accuracy: 0.3038 - val_loss: 2.3821 - val_categorical_accuracy: 0.2089\n",
      "Epoch 7/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.8831 - categorical_accuracy: 0.3671 - val_loss: 2.3970 - val_categorical_accuracy: 0.2468\n",
      "Epoch 8/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.8334 - categorical_accuracy: 0.3671 - val_loss: 2.3739 - val_categorical_accuracy: 0.2215\n",
      "Epoch 9/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.7650 - categorical_accuracy: 0.3972 - val_loss: 2.4496 - val_categorical_accuracy: 0.1646\n",
      "Epoch 10/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.6824 - categorical_accuracy: 0.4430 - val_loss: 2.4620 - val_categorical_accuracy: 0.1582\n",
      "Epoch 11/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.6541 - categorical_accuracy: 0.4272 - val_loss: 2.4521 - val_categorical_accuracy: 0.1709\n",
      "Epoch 12/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.5868 - categorical_accuracy: 0.4589 - val_loss: 2.4042 - val_categorical_accuracy: 0.1962\n",
      "Epoch 13/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.6057 - categorical_accuracy: 0.4573 - val_loss: 2.4845 - val_categorical_accuracy: 0.1962\n",
      "Epoch 14/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.5367 - categorical_accuracy: 0.4794 - val_loss: 2.4801 - val_categorical_accuracy: 0.1835\n",
      "Epoch 15/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.5034 - categorical_accuracy: 0.4921 - val_loss: 2.5364 - val_categorical_accuracy: 0.1772\n",
      "Epoch 16/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.4431 - categorical_accuracy: 0.5016 - val_loss: 2.6500 - val_categorical_accuracy: 0.1646\n",
      "Epoch 17/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.4173 - categorical_accuracy: 0.5364 - val_loss: 2.6012 - val_categorical_accuracy: 0.1456\n",
      "Epoch 18/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.3960 - categorical_accuracy: 0.5316 - val_loss: 2.6820 - val_categorical_accuracy: 0.1203\n",
      "Epoch 19/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.3989 - categorical_accuracy: 0.5301 - val_loss: 2.7195 - val_categorical_accuracy: 0.1772\n",
      "Epoch 20/20\n",
      "632/632 [==============================] - 4s 6ms/sample - loss: 1.3289 - categorical_accuracy: 0.5633 - val_loss: 2.5824 - val_categorical_accuracy: 0.2342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf157decd0>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model.h5')\n",
    "\n",
    "trainer(model, epochs=20, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File model_ep04_val0.25.index uploaded to physio-bucket as model_ep04_val0.25.index.\n",
      "File model_ep04_val0.25.data-00000-of-00001 uploaded to physio-bucket as model_ep04_val0.25.data-00000-of-00001.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights=['model_ep04_val0.25.index','model_ep04_val0.25.data-00000-of-00001']\n",
    "\n",
    "[upload_blob(data['bucket'],w,w) for w in weights]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 200, 6)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size= 0.3, random_state=1992)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
