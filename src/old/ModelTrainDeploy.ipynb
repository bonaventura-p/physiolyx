{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file sets up the directories, imports py libs, runs push_and_build.sh, starts the session, does training and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir opt\n",
    "!mkdir opt/ml\n",
    "!mkdir opt/ml/input\n",
    "!mkdir opt/ml/input/data\n",
    "!mkdir opt/ml/input/data/training\n",
    "!mkdir opt/ml/model\n",
    "!mkdir opt/ml/output\n",
    "!mkdir opt/program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir packages\n",
    "#os.chdir('packages')\n",
    "#!pip install tensorflow -t ./\n",
    "#!pip install keras\n",
    "#!pip install gunicorn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "\n",
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/race-vr/container'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up-to-date with 'origin/master'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "\n",
      "\t\u001b[31mmodified:   .ipynb_checkpoints/setup-checkpoint.ipynb\u001b[m\n",
      "\t\u001b[31mmodified:   setup.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "! git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/race-vr/container'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  215.8MB\n",
      "Step 1/8 : FROM ubuntu:16.04\n",
      " ---> 77be327e4b63\n",
      "Step 2/8 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f458b94b526e\n",
      "Step 3/8 : RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py &&     pip install numpy scipy==1.2.2 scikit-learn keras pandas flask gevent gunicorn tensorflow &&         rm -rf /root/.cache\n",
      " ---> Using cache\n",
      " ---> 90cd03d00a83\n",
      "Step 4/8 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 8b3992bef087\n",
      "Step 5/8 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> dadd7fd1b518\n",
      "Step 6/8 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 45a6c36d03d7\n",
      "Step 7/8 : COPY algorithms /opt/program\n",
      " ---> 1d108ed17dad\n",
      "Step 8/8 : WORKDIR /opt/program\n",
      " ---> Running in 6e358aef9cc3\n",
      "Removing intermediate container 6e358aef9cc3\n",
      " ---> 2d74709893c8\n",
      "Successfully built 2d74709893c8\n",
      "Successfully tagged sagemaker-lstm:latest\n",
      "The push refers to repository [264421419663.dkr.ecr.us-east-1.amazonaws.com/sagemaker-lstm]\n",
      "\n",
      "\u001b[1B90859607: Preparing \n",
      "\u001b[1Bb79372d3: Preparing \n",
      "\u001b[1B58efaccb: Preparing \n",
      "\u001b[1Badcb66cb: Preparing \n",
      "\u001b[1B85385151: Preparing \n",
      "\u001b[1Bd8f00d7e: Preparing \n",
      "\u001b[7B90859607: Pushed lready exists 3kBA\u001b[1K\u001b[K\u001b[7A\u001b[1K\u001b[Klatest: digest: sha256:278f32878055302e7c543420feb3be9445818fcad1abadad19253da0eeb96574 size: 1783\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/ec2-user/SageMaker/race-vr/container')\n",
    "! sh build_and_push.sh sagemaker-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ec2-user/SageMaker/race-vr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "bucket = \"sagemaker-wisdm2\" #from get_data.ipynb\n",
    "data_location = 's3://{}/data'.format(bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-lstm:latest'.format(account, region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.m5.4xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(bucket),\n",
    "                       sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 19:39:56 Starting - Starting the training job...\n",
      "2020-04-01 19:39:57 Starting - Launching requested ML instances......\n",
      "2020-04-01 19:41:03 Starting - Preparing the instances for training...\n",
      "2020-04-01 19:41:54 Downloading - Downloading input data\n",
      "2020-04-01 19:41:54 Training - Downloading the training image......\n",
      "2020-04-01 19:42:48 Training - Training image download completed. Training in progress.\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34m2020-04-01 19:42:49.522368: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-04-01 19:42:49.522441: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-04-01 19:42:49.522450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mPreprocessing started\u001b[0m\n",
      "\u001b[34m0.0 0.0 0.0\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python2.7/dist-packages/scipy/stats/stats.py:248: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\u001b[0m\n",
      "\u001b[34mPreprocessing completed\u001b[0m\n",
      "\u001b[34muser                     17\u001b[0m\n",
      "\u001b[34mactivity            Walking\u001b[0m\n",
      "\u001b[34mtimestamp    35111782361000\u001b[0m\n",
      "\u001b[34mx-axis                 3.68\u001b[0m\n",
      "\u001b[34my-axis                 8.43\u001b[0m\n",
      "\u001b[34mz-axis                -1.65\u001b[0m\n",
      "\u001b[34mName: 0, dtype: object\u001b[0m\n",
      "\u001b[34m2020-04-01 19:43:05.967852: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-04-01 19:43:05.967879: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2020-04-01 19:43:05.967898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-226-64.ec2.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2020-04-01 19:43:05.968200: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34m2020-04-01 19:43:05.997736: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499995000 Hz\u001b[0m\n",
      "\u001b[34m2020-04-01 19:43:05.998644: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x105b7730 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\u001b[0m\n",
      "\u001b[34m2020-04-01 19:43:05.998668: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\u001b[0m\n",
      "\u001b[34m5\u001b[0m\n",
      "\u001b[34mTrain on 17290 samples, validate on 7411 samples\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[34m 1000/17290 [>.............................] - ETA: 48s - loss: 1.7005 - accuracy: 0.3210\u001b[0m\n",
      "\u001b[34m 2000/17290 [==>...........................] - ETA: 35s - loss: 1.6568 - accuracy: 0.3155\u001b[0m\n",
      "\u001b[34m 3000/17290 [====>.........................] - ETA: 30s - loss: 1.6362 - accuracy: 0.3140\u001b[0m\n",
      "\u001b[34m 4000/17290 [=====>........................] - ETA: 26s - loss: 1.6179 - accuracy: 0.3350\u001b[0m\n",
      "\u001b[34m 5000/17290 [=======>......................] - ETA: 23s - loss: 1.6065 - accuracy: 0.3506\u001b[0m\n",
      "\u001b[34m 6000/17290 [=========>....................] - ETA: 21s - loss: 1.5912 - accuracy: 0.3600\u001b[0m\n",
      "\u001b[34m 7000/17290 [===========>..................] - ETA: 18s - loss: 1.5805 - accuracy: 0.3649\u001b[0m\n",
      "\u001b[34m 8000/17290 [============>.................] - ETA: 16s - loss: 1.5724 - accuracy: 0.3672\u001b[0m\n",
      "\u001b[34m 9000/17290 [==============>...............] - ETA: 14s - loss: 1.5688 - accuracy: 0.3686\u001b[0m\n",
      "\u001b[34m10000/17290 [================>.............] - ETA: 12s - loss: 1.5610 - accuracy: 0.3704\u001b[0m\n",
      "\u001b[34m11000/17290 [==================>...........] - ETA: 11s - loss: 1.5531 - accuracy: 0.3743\u001b[0m\n",
      "\u001b[34m12000/17290 [===================>..........] - ETA: 9s - loss: 1.5477 - accuracy: 0.3765 \u001b[0m\n",
      "\u001b[34m13000/17290 [=====================>........] - ETA: 7s - loss: 1.5446 - accuracy: 0.3770\u001b[0m\n",
      "\u001b[34m14000/17290 [=======================>......] - ETA: 5s - loss: 1.5413 - accuracy: 0.3787\u001b[0m\n",
      "\u001b[34m15000/17290 [=========================>....] - ETA: 4s - loss: 1.5390 - accuracy: 0.3792\u001b[0m\n",
      "\u001b[34m16000/17290 [==========================>...] - ETA: 2s - loss: 1.5364 - accuracy: 0.3799\u001b[0m\n",
      "\u001b[34m17000/17290 [============================>.] - ETA: 0s - loss: 1.5340 - accuracy: 0.3789\u001b[0m\n",
      "\u001b[34m17290/17290 [==============================] - 34s 2ms/step - loss: 1.5327 - accuracy: 0.3792 - val_loss: 1.5047 - val_accuracy: 0.3734\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m 1000/17290 [>.............................] - ETA: 27s - loss: 1.4872 - accuracy: 0.3840\u001b[0m\n",
      "\u001b[34m 2000/17290 [==>...........................] - ETA: 25s - loss: 1.4931 - accuracy: 0.3830\u001b[0m\n",
      "\u001b[34m 3000/17290 [====>.........................] - ETA: 23s - loss: 1.4906 - accuracy: 0.3807\u001b[0m\n",
      "\u001b[34m 4000/17290 [=====>........................] - ETA: 22s - loss: 1.4923 - accuracy: 0.3848\u001b[0m\n",
      "\u001b[34m 5000/17290 [=======>......................] - ETA: 20s - loss: 1.4877 - accuracy: 0.3862\u001b[0m\n",
      "\u001b[34m 6000/17290 [=========>....................] - ETA: 18s - loss: 1.4839 - accuracy: 0.3895\u001b[0m\n",
      "\u001b[34m 7000/17290 [===========>..................] - ETA: 17s - loss: 1.4840 - accuracy: 0.3913\u001b[0m\n",
      "\u001b[34m 8000/17290 [============>.................] - ETA: 15s - loss: 1.4779 - accuracy: 0.3956\u001b[0m\n",
      "\u001b[34m 9000/17290 [==============>...............] - ETA: 13s - loss: 1.4821 - accuracy: 0.3936\u001b[0m\n",
      "\u001b[34m10000/17290 [================>.............] - ETA: 12s - loss: 1.4854 - accuracy: 0.3917\u001b[0m\n",
      "\u001b[34m11000/17290 [==================>...........] - ETA: 10s - loss: 1.4848 - accuracy: 0.3921\u001b[0m\n",
      "\u001b[34m12000/17290 [===================>..........] - ETA: 8s - loss: 1.4851 - accuracy: 0.3921 \u001b[0m\n",
      "\u001b[34m13000/17290 [=====================>........] - ETA: 7s - loss: 1.4861 - accuracy: 0.3928\u001b[0m\n",
      "\u001b[34m14000/17290 [=======================>......] - ETA: 5s - loss: 1.4878 - accuracy: 0.3909\u001b[0m\n",
      "\u001b[34m15000/17290 [=========================>....] - ETA: 3s - loss: 1.4877 - accuracy: 0.3907\u001b[0m\n",
      "\u001b[34m16000/17290 [==========================>...] - ETA: 2s - loss: 1.4875 - accuracy: 0.3907\u001b[0m\n",
      "\u001b[34m17000/17290 [============================>.] - ETA: 0s - loss: 1.4884 - accuracy: 0.3910\u001b[0m\n",
      "\u001b[34m17290/17290 [==============================] - 32s 2ms/step - loss: 1.4876 - accuracy: 0.3916 - val_loss: 1.5015 - val_accuracy: 0.3734\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m 1000/17290 [>.............................] - ETA: 25s - loss: 1.5011 - accuracy: 0.3810\u001b[0m\n",
      "\u001b[34m 2000/17290 [==>...........................] - ETA: 24s - loss: 1.5103 - accuracy: 0.3860\u001b[0m\n",
      "\u001b[34m 3000/17290 [====>.........................] - ETA: 22s - loss: 1.5027 - accuracy: 0.3773\u001b[0m\n",
      "\u001b[34m 4000/17290 [=====>........................] - ETA: 21s - loss: 1.5059 - accuracy: 0.3767\u001b[0m\n",
      "\u001b[34m 5000/17290 [=======>......................] - ETA: 19s - loss: 1.5001 - accuracy: 0.3774\u001b[0m\n",
      "\u001b[34m 6000/17290 [=========>....................] - ETA: 18s - loss: 1.5001 - accuracy: 0.3800\u001b[0m\n",
      "\u001b[34m 7000/17290 [===========>..................] - ETA: 16s - loss: 1.4973 - accuracy: 0.3841\u001b[0m\n",
      "\u001b[34m 8000/17290 [============>.................] - ETA: 15s - loss: 1.4928 - accuracy: 0.3874\u001b[0m\n",
      "\u001b[34m 9000/17290 [==============>...............] - ETA: 13s - loss: 1.4917 - accuracy: 0.3878\u001b[0m\n",
      "\u001b[34m10000/17290 [================>.............] - ETA: 11s - loss: 1.4916 - accuracy: 0.3881\u001b[0m\n",
      "\u001b[34m11000/17290 [==================>...........] - ETA: 10s - loss: 1.4903 - accuracy: 0.3879\u001b[0m\n",
      "\u001b[34m12000/17290 [===================>..........] - ETA: 8s - loss: 1.4907 - accuracy: 0.3884 \u001b[0m\n",
      "\u001b[34m13000/17290 [=====================>........] - ETA: 6s - loss: 1.4930 - accuracy: 0.3875\u001b[0m\n",
      "\u001b[34m14000/17290 [=======================>......] - ETA: 5s - loss: 1.4919 - accuracy: 0.3874\u001b[0m\n",
      "\u001b[34m15000/17290 [=========================>....] - ETA: 3s - loss: 1.4885 - accuracy: 0.3890\u001b[0m\n",
      "\u001b[34m16000/17290 [==========================>...] - ETA: 2s - loss: 1.4878 - accuracy: 0.3902\u001b[0m\n",
      "\u001b[34m17000/17290 [============================>.] - ETA: 0s - loss: 1.4865 - accuracy: 0.3914\u001b[0m\n",
      "\u001b[34m17290/17290 [==============================] - 32s 2ms/step - loss: 1.4865 - accuracy: 0.3916 - val_loss: 1.5019 - val_accuracy: 0.3734\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m 1000/17290 [>.............................] - ETA: 27s - loss: 1.4693 - accuracy: 0.4010\u001b[0m\n",
      "\u001b[34m 2000/17290 [==>...........................] - ETA: 25s - loss: 1.4844 - accuracy: 0.3835\u001b[0m\n",
      "\u001b[34m 3000/17290 [====>.........................] - ETA: 23s - loss: 1.4916 - accuracy: 0.3833\u001b[0m\n",
      "\u001b[34m 4000/17290 [=====>........................] - ETA: 22s - loss: 1.5017 - accuracy: 0.3865\u001b[0m\n",
      "\u001b[34m 5000/17290 [=======>......................] - ETA: 20s - loss: 1.5064 - accuracy: 0.3798\u001b[0m\n",
      "\u001b[34m 6000/17290 [=========>....................] - ETA: 18s - loss: 1.5059 - accuracy: 0.3837\u001b[0m\n",
      "\u001b[34m 7000/17290 [===========>..................] - ETA: 17s - loss: 1.4967 - accuracy: 0.3874\u001b[0m\n",
      "\u001b[34m 8000/17290 [============>.................] - ETA: 15s - loss: 1.4970 - accuracy: 0.3885\u001b[0m\n",
      "\u001b[34m 9000/17290 [==============>...............] - ETA: 13s - loss: 1.4974 - accuracy: 0.3887\u001b[0m\n",
      "\u001b[34m10000/17290 [================>.............] - ETA: 12s - loss: 1.4958 - accuracy: 0.3891\u001b[0m\n",
      "\u001b[34m11000/17290 [==================>...........] - ETA: 10s - loss: 1.4959 - accuracy: 0.3882\u001b[0m\n",
      "\u001b[34m12000/17290 [===================>..........] - ETA: 8s - loss: 1.4911 - accuracy: 0.3906 \u001b[0m\n",
      "\u001b[34m13000/17290 [=====================>........] - ETA: 7s - loss: 1.4911 - accuracy: 0.3906\u001b[0m\n",
      "\u001b[34m14000/17290 [=======================>......] - ETA: 5s - loss: 1.4893 - accuracy: 0.3911\u001b[0m\n",
      "\u001b[34m15000/17290 [=========================>....] - ETA: 3s - loss: 1.4894 - accuracy: 0.3901\u001b[0m\n",
      "\u001b[34m16000/17290 [==========================>...] - ETA: 2s - loss: 1.4888 - accuracy: 0.3906\u001b[0m\n",
      "\u001b[34m17000/17290 [============================>.] - ETA: 0s - loss: 1.4861 - accuracy: 0.3915\u001b[0m\n",
      "\u001b[34m17290/17290 [==============================] - 32s 2ms/step - loss: 1.4865 - accuracy: 0.3916 - val_loss: 1.5009 - val_accuracy: 0.3734\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\u001b[34m 1000/17290 [>.............................] - ETA: 26s - loss: 1.4587 - accuracy: 0.3930\u001b[0m\n",
      "\u001b[34m 2000/17290 [==>...........................] - ETA: 24s - loss: 1.4809 - accuracy: 0.3835\u001b[0m\n",
      "\u001b[34m 3000/17290 [====>.........................] - ETA: 23s - loss: 1.4767 - accuracy: 0.3873\u001b[0m\n",
      "\u001b[34m 4000/17290 [=====>........................] - ETA: 21s - loss: 1.4913 - accuracy: 0.3820\u001b[0m\n",
      "\u001b[34m 5000/17290 [=======>......................] - ETA: 20s - loss: 1.4819 - accuracy: 0.3866\u001b[0m\n",
      "\u001b[34m 6000/17290 [=========>....................] - ETA: 18s - loss: 1.4832 - accuracy: 0.3857\u001b[0m\n",
      "\u001b[34m 7000/17290 [===========>..................] - ETA: 16s - loss: 1.4829 - accuracy: 0.3881\u001b[0m\n",
      "\u001b[34m 8000/17290 [============>.................] - ETA: 15s - loss: 1.4838 - accuracy: 0.3886\u001b[0m\n",
      "\u001b[34m 9000/17290 [==============>...............] - ETA: 13s - loss: 1.4803 - accuracy: 0.3910\u001b[0m\n",
      "\u001b[34m10000/17290 [================>.............] - ETA: 11s - loss: 1.4826 - accuracy: 0.3926\u001b[0m\n",
      "\u001b[34m11000/17290 [==================>...........] - ETA: 10s - loss: 1.4802 - accuracy: 0.3928\u001b[0m\n",
      "\u001b[34m12000/17290 [===================>..........] - ETA: 8s - loss: 1.4810 - accuracy: 0.3914 \u001b[0m\n",
      "\u001b[34m13000/17290 [=====================>........] - ETA: 7s - loss: 1.4802 - accuracy: 0.3926\u001b[0m\n",
      "\u001b[34m14000/17290 [=======================>......] - ETA: 5s - loss: 1.4814 - accuracy: 0.3917\u001b[0m\n",
      "\u001b[34m15000/17290 [=========================>....] - ETA: 3s - loss: 1.4838 - accuracy: 0.3926\u001b[0m\n",
      "\u001b[34m16000/17290 [==========================>...] - ETA: 2s - loss: 1.4847 - accuracy: 0.3922\u001b[0m\n",
      "\n",
      "2020-04-01 19:45:56 Uploading - Uploading generated training model\n",
      "2020-04-01 19:45:56 Completed - Training job completed\n",
      "\u001b[34m17000/17290 [============================>.] - ETA: 0s - loss: 1.4867 - accuracy: 0.3912\u001b[0m\n",
      "\u001b[34m17290/17290 [==============================] - 32s 2ms/step - loss: 1.4863 - accuracy: 0.3916 - val_loss: 1.5020 - val_accuracy: 0.3734\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "Training seconds: 262\n",
      "Billable seconds: 262\n"
     ]
    }
   ],
   "source": [
    "lstm.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally we export the parameters we need for deployment as json and upload it to s3\n",
    "outjson = {'jobTrainingId': lstm._current_job_name, 'outputPath': \"s3://{}/output\".format(bucket), 'imageLocation':image}\n",
    "\n",
    "with open(\"hyperParameters.json\", \"w\") as json_file:\n",
    "    json.dump(outjson, json_file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ec2-user/SageMaker/race-vr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"sagemaker-wisdm2\"\n",
    "data_location = 's3://{}'.format(bucket)\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "s3.Bucket(bucket).upload_file(\"hyperParameters.json\",\"hyperParameters.json\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S3location = 'output/' + outjson['jobTrainingId'] + '/output/'\n",
    "s3.Bucket(bucket).download_file(model_S3location + 'model.tar.gz', '/home/ec2-user/SageMaker/race-vr/opt/ml/model/model.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ec2-user/SageMaker/race-vr/opt/ml/model/')\n",
    "! tar -xf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ec2-user/SageMaker/race-vr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = lstm.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.Bucket(bucket).download_file('data/df0.csv', '/home/ec2-user/SageMaker/race-vr/df0.csv')\n",
    "\n",
    "columns = ['user','activity','timestamp', 'x-axis', 'y-axis', 'z-axis']\n",
    "test_data = pd.read_csv('misc/test.csv', header=0, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x-axis</th>\n",
       "      <th>y-axis</th>\n",
       "      <th>z-axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49105962326000</td>\n",
       "      <td>-0.694638</td>\n",
       "      <td>12.680544</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106062271000</td>\n",
       "      <td>5.012288</td>\n",
       "      <td>11.264028</td>\n",
       "      <td>0.953424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106112167000</td>\n",
       "      <td>4.903325</td>\n",
       "      <td>10.882658</td>\n",
       "      <td>-0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106222305000</td>\n",
       "      <td>-0.612916</td>\n",
       "      <td>18.496431</td>\n",
       "      <td>3.023717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106332290000</td>\n",
       "      <td>-1.184970</td>\n",
       "      <td>12.108489</td>\n",
       "      <td>7.205164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user activity       timestamp    x-axis     y-axis    z-axis\n",
       "0    33  Jogging  49105962326000 -0.694638  12.680544  0.503953\n",
       "1    33  Jogging  49106062271000  5.012288  11.264028  0.953424\n",
       "2    33  Jogging  49106112167000  4.903325  10.882658 -0.081722\n",
       "3    33  Jogging  49106222305000 -0.612916  18.496431  3.023717\n",
       "4    33  Jogging  49106332290000 -1.184970  12.108489  7.205164"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def testPreprocess(df, timeSteps=400, step=40, testSize=0.2):\n",
    "    '''preprocessing and split'''\n",
    "    features=3\n",
    "    RANDOM_SEED = 1992\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    print('Preprocessing started')\n",
    "    \n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    #normalise data otherwise loss= nan\n",
    "    df['z-axis'] = df['z-axis'].astype(float)\n",
    "\n",
    "    df['x-axis'] = (df['x-axis'] - df['x-axis'].min())/(df['x-axis'].max()-df['x-axis'].min())\n",
    "    df['y-axis'] = (df['y-axis'] - df['y-axis'].min())/(df['y-axis'].max()-df['y-axis'].min())\n",
    "    df['z-axis'] = (df['z-axis'] - df['z-axis'].min())/(df['z-axis'].max()-df['z-axis'].min())\n",
    "    \n",
    "    print( df['x-axis'].min(), df['y-axis'].min(), df['z-axis'].min())\n",
    "    #redo it with  df.shape[0]%20 ==0 trying out different divisors (12 16 18 20 24) and a while to get to the largest\n",
    "\n",
    "    #we reshape into 3d arrays of length evual to timesteps. final df is= (N*timesteps*3)\n",
    "    for i in range(0, len(df) - timeSteps, step):\n",
    "        xs = df['x-axis'].values[i: i + timeSteps]\n",
    "        ys = df['y-axis'].values[i: i + timeSteps]\n",
    "        zs = df['z-axis'].values[i: i + timeSteps]\n",
    "        label = stats.mode(df['activity'][i: i + timeSteps])[0][0]\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, timeSteps, features)\n",
    "    labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "\n",
    "    print('Preprocessing completed')\n",
    "\n",
    "    return train_test_split(\n",
    "        reshaped_segments, labels, test_size=testSize, random_state=RANDOM_SEED)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing started\n",
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = testPreprocess(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 400, 3)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = X_train[0:10]\n",
    "\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
